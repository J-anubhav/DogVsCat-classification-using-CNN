{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d11369a",
   "metadata": {},
   "source": [
    "# New model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845eaafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:55:06.530934: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-14 16:55:07.623244: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/anubhav_jha/tf-gpu/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-14 16:55:11.231737: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263eb4b",
   "metadata": {},
   "source": [
    "## Load and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dbebdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load data with improved preprocessing\"\"\"\n",
    "    try:\n",
    "        X_train = np.loadtxt('input.csv', delimiter=',')\n",
    "        X_test = np.loadtxt('input_test.csv', delimiter=',')\n",
    "        Y_train = np.loadtxt('labels.csv', delimiter=',')\n",
    "        Y_test = np.loadtxt('labels_test.csv', delimiter=',')\n",
    "    except ValueError:\n",
    "        import pandas as pd\n",
    "        X_train = pd.read_csv('input.csv').to_numpy()\n",
    "        X_test = pd.read_csv('input_test.csv').to_numpy()\n",
    "        Y_train = pd.read_csv('labels.csv').to_numpy()\n",
    "        Y_test = pd.read_csv('labels_test.csv').to_numpy()\n",
    "    \n",
    "    # Reshape data\n",
    "    X_train = X_train.reshape(-1, 100, 100, 3)\n",
    "    X_test = X_test.reshape(-1, 100, 100, 3)\n",
    "    Y_train = Y_train.reshape(-1, 1)\n",
    "    Y_test = Y_test.reshape(-1, 1)\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Per-channel normalization \n",
    "    # Compute mean and std per channel on training data\n",
    "    train_mean = np.mean(X_train, axis=(0, 1, 2))\n",
    "    train_std = np.std(X_train, axis=(0, 1, 2))\n",
    "    \n",
    "    # Apply normalization\n",
    "    X_train = (X_train - train_mean) / (train_std + 1e-7)\n",
    "    X_test = (X_test - train_mean) / (train_std + 1e-7)\n",
    "    \n",
    "    print(f\"Training data shape: {X_train.shape}\")\n",
    "    print(f\"Test data shape: {X_test.shape}\")\n",
    "    print(f\"Training labels distribution: {np.bincount(Y_train.astype(int).flatten())}\")\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d8e8e",
   "metadata": {},
   "source": [
    "# data augmentatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b6d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators(X_train, Y_train, X_test, Y_test):\n",
    "    \"\"\"Create data generators with more aggressive augmentation\"\"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.3,\n",
    "        shear_range=0.2,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # No augmentation for validation data\n",
    "    val_datagen = ImageDataGenerator()\n",
    "    \n",
    "    train_generator = train_datagen.flow(X_train, Y_train, batch_size=32)\n",
    "    val_generator = val_datagen.flow(X_test, Y_test, batch_size=32, shuffle=False)\n",
    "    \n",
    "    return train_generator, val_generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472e3f9",
   "metadata": {},
   "source": [
    "# CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89fbc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_improved_model():\n",
    "    \"\"\"Create an improved CNN model with better architecture\"\"\"\n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Global Average Pooling instead of Flatten\n",
    "        GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Dense layers\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba439f73",
   "metadata": {},
   "source": [
    "# Transfer learning model (VGG16-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "608f81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_learning_model():\n",
    "    \"\"\"Create a transfer learning model using VGG16\"\"\"\n",
    "    from tensorflow.keras.applications import VGG16\n",
    "    from tensorflow.keras.models import Model\n",
    "    \n",
    "    # Load pre-trained VGG16 model\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Add custom classifier\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1208d97c",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b748c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, val_generator, model_name=\"enhanced_model\"):\n",
    "    \"\"\"Train the model with advanced callbacks\"\"\"\n",
    "    \n",
    "    # Compile with optimized parameters\n",
    "    optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Advanced callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            f'{model_name}_best.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=100,  # More epochs with early stopping\n",
    "        validation_data=val_generator,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bce0c3",
   "metadata": {},
   "source": [
    "# Evaluation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2362f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_visualize(model, X_test, Y_test):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(y_pred.flatten() == Y_test.flatten())\n",
    "    print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(Y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Dog', 'Cat'], yticklabels=['Dog', 'Cat'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix - Enhanced Model')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(Y_test, y_pred, target_names=['Dog', 'Cat']))\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581508c7",
   "metadata": {},
   "source": [
    "# Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10866da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_prediction(models, X_test):\n",
    "    \"\"\"Create ensemble predictions from multiple models\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        pred = model.predict(X_test)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    return (ensemble_pred > 0.5).astype(int)\n",
    "\n",
    "# Main execution function\n",
    "def main():\n",
    "    \"\"\"Main function to run the entire pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"ENHANCED DOG VS CAT CLASSIFICATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Step 1: Load and preprocess data\n",
    "    print(\"\\n1. Loading and preprocessing data...\")\n",
    "    X_train, X_test, Y_train, Y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Step 2: Create data generators\n",
    "    print(\"\\n2. Creating data generators...\")\n",
    "    train_gen, val_gen = create_data_generators(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "    # Step 3: Train improved CNN model\n",
    "    print(\"\\n3. Training improved CNN model...\")\n",
    "    improved_model = create_improved_model()\n",
    "    print(f\"Model parameters: {improved_model.count_params():,}\")\n",
    "    \n",
    "    history1 = train_model(improved_model, train_gen, val_gen, \"improved_cnn\")\n",
    "    acc1 = evaluate_and_visualize(improved_model, X_test, Y_test)\n",
    "    \n",
    "    # Step 4: Train transfer learning model\n",
    "    print(\"\\n4. Training transfer learning model...\")\n",
    "    transfer_model = create_transfer_learning_model()\n",
    "    print(f\"Transfer model parameters: {transfer_model.count_params():,}\")\n",
    "    \n",
    "    # Recreate generators for transfer learning\n",
    "    train_gen2, val_gen2 = create_data_generators(X_train, Y_train, X_test, Y_test)\n",
    "    history2 = train_model(transfer_model, train_gen2, val_gen2, \"transfer_learning\")\n",
    "    acc2 = evaluate_and_visualize(transfer_model, X_test, Y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3857a4",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "974254d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_prediction(models, X_test):\n",
    "    \"\"\"Create ensemble predictions from multiple models\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        pred = model.predict(X_test)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    return (ensemble_pred > 0.5).astype(int)\n",
    "\n",
    "# Main execution function\n",
    "def main():\n",
    "    \"\"\"Main function to run the entire pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"ENHANCED DOG VS CAT CLASSIFICATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Step 1: Load and preprocess data\n",
    "    print(\"\\n1. Loading and preprocessing data...\")\n",
    "    X_train, X_test, Y_train, Y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Step 2: Create data generators\n",
    "    print(\"\\n2. Creating data generators...\")\n",
    "    train_gen, val_gen = create_data_generators(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "    # Step 3: Train improved CNN model\n",
    "    print(\"\\n3. Training improved CNN model...\")\n",
    "    improved_model = create_improved_model()\n",
    "    print(f\"Model parameters: {improved_model.count_params():,}\")\n",
    "    \n",
    "    history1 = train_model(improved_model, train_gen, val_gen, \"improved_cnn\")\n",
    "    acc1 = evaluate_and_visualize(improved_model, X_test, Y_test)\n",
    "    \n",
    "    # Step 4: Train transfer learning model\n",
    "    print(\"\\n4. Training transfer learning model...\")\n",
    "    transfer_model = create_transfer_learning_model()\n",
    "    print(f\"Transfer model parameters: {transfer_model.count_params():,}\")\n",
    "    \n",
    "    # Recreate generators for transfer learning\n",
    "    train_gen2, val_gen2 = create_data_generators(X_train, Y_train, X_test, Y_test)\n",
    "    history2 = train_model(transfer_model, train_gen2, val_gen2, \"transfer_learning\")\n",
    "    acc2 = evaluate_and_visualize(transfer_model, X_test, Y_test)\n",
    "    \n",
    "    # Step 5: Ensemble prediction\n",
    "    print(\"\\n5. Creating ensemble prediction...\")\n",
    "    ensemble_pred = create_ensemble_prediction([improved_model, transfer_model], X_test)\n",
    "    ensemble_acc = np.mean(ensemble_pred.flatten() == Y_test.flatten())\n",
    "    print(f\"Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
    "    \n",
    "    # Final comparison\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL RESULTS COMPARISON:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Improved CNN Accuracy: {acc1:.4f}\")\n",
    "    print(f\"Transfer Learning Accuracy: {acc2:.4f}\")\n",
    "    print(f\"Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return improved_model, transfer_model, ensemble_acc\n",
    "\n",
    "# Additional utility functions\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_prediction_examples(model, X_test, Y_test, num_examples=8):\n",
    "    \"\"\"Show prediction examples\"\"\"\n",
    "    indices = np.random.choice(len(X_test), num_examples, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        \n",
    "        # Denormalize image for display (if normalized)\n",
    "        img = X_test[idx]\n",
    "        if img.min() < 0:  # If normalized\n",
    "            img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        \n",
    "        pred_prob = model.predict(np.expand_dims(X_test[idx], axis=0))[0][0]\n",
    "        pred_class = \"Cat\" if pred_prob > 0.5 else \"Dog\"\n",
    "        true_class = \"Cat\" if Y_test[idx][0] > 0.5 else \"Dog\"\n",
    "        \n",
    "        color = 'green' if pred_class == true_class else 'red'\n",
    "        plt.title(f'True: {true_class}\\nPred: {pred_class} ({pred_prob:.2f})', \n",
    "                 color=color)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad69ea25",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ENHANCED DOG VS CAT CLASSIFICATION\n",
      "==================================================\n",
      "\n",
      "1. Loading and preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    improved_model, transfer_model, final_accuracy = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Koi model nahi mila!\n",
      "Pehle apna model load/train karo\n",
      "\n",
      "💡 Agar aur test karna hai to run karo:\n",
      "simple_prediction_test(your_model, X_test, Y_test)\n"
     ]
    }
   ],
   "source": [
    "def simple_prediction_test(model, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    Simple function jo sirf ek random image leta hai aur prediction check karta hai\n",
    "    No heavy processing, no multiple images - bas ek quick test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Random image select karo\n",
    "    idx = random.randint(0, len(X_test) - 1)\n",
    "    \n",
    "    # Image prepare karo display ke liye\n",
    "    test_image = X_test[idx].copy()\n",
    "    if test_image.min() < 0:\n",
    "        test_image = (test_image - test_image.min()) / (test_image.max() - test_image.min())\n",
    "    \n",
    "    # Model se prediction lo\n",
    "    prediction = model.predict(X_test[idx:idx+1], verbose=0)[0][0]\n",
    "    actual_label = Y_test[idx][0]\n",
    "    \n",
    "    # Classes determine karo\n",
    "    if prediction > 0.5:\n",
    "        predicted_class = \"Cat\"\n",
    "        confidence = prediction\n",
    "    else:\n",
    "        predicted_class = \"Dog\" \n",
    "        confidence = 1 - prediction\n",
    "    \n",
    "    if actual_label > 0.5:\n",
    "        actual_class = \"Cat\"\n",
    "    else:\n",
    "        actual_class = \"Dog\"\n",
    "    \n",
    "    # Result check karo\n",
    "    is_correct = (predicted_class == actual_class)\n",
    "    \n",
    "    # Simple display\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(test_image)\n",
    "    \n",
    "    # Title me sab kuch batao\n",
    "    if is_correct:\n",
    "        result_text = f\"✅ SAHI HAI!\\n\"\n",
    "        title_color = 'green'\n",
    "    else:\n",
    "        result_text = f\"❌ GALAT HAI!\\n\"\n",
    "        title_color = 'red'\n",
    "    \n",
    "    result_text += f\"Actual: {actual_class}\\n\"\n",
    "    result_text += f\"Model ne kaha: {predicted_class}\\n\"\n",
    "    result_text += f\"Confidence: {confidence:.1%}\"\n",
    "    \n",
    "    plt.title(result_text, fontsize=14, fontweight='bold', color=title_color)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Console me bhi print karo\n",
    "    # print(\"=\"*50)\n",
    "    # if is_correct:\n",
    "    #     print(\"🎉 MODEL SAHI HAI!\")\n",
    "    # else:\n",
    "    #     print(\"😞 MODEL GALAT HAI!\")\n",
    "    \n",
    "    print(f\"Actual label: {actual_class}\")\n",
    "    print(f\"Model prediction: {predicted_class}\")\n",
    "    print(f\"Confidence: {confidence:.1%}\")\n",
    "    print(f\"Raw score: {prediction:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return is_correct, predicted_class, actual_class, confidence\n",
    "\n",
    "\n",
    "def quick_test_multiple_times(model, X_test, Y_test, num_tests=5):\n",
    "    \"\"\"\n",
    "    Agar aap chahte hain to multiple times test kar sakte hain\n",
    "    \"\"\"\n",
    "    correct_count = 0\n",
    "    \n",
    "    print(f\"\\n🔄 {num_tests} random images test kar rahe hain...\\n\")\n",
    "    \n",
    "    for i in range(num_tests):\n",
    "        print(f\"Test {i+1}:\")\n",
    "        is_correct, pred, actual, conf = simple_prediction_test(model, X_test, Y_test)\n",
    "        if is_correct:\n",
    "            correct_count += 1\n",
    "        print()  # Empty line for spacing\n",
    "    \n",
    "    accuracy = correct_count / num_tests\n",
    "    print(f\"📊 RESULT: {correct_count}/{num_tests} sahi ({accuracy:.1%} accuracy)\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# USAGE - Sirf ye line run karni hai\n",
    "# =============================================================================\n",
    "\n",
    "# Check karo ki model aur data available hai\n",
    "try:\n",
    "    # Ye automatically detect karega available model\n",
    "    available_models = []\n",
    "    for name in ['transfer_model', 'improved_model', 'model', 'best_model']:\n",
    "        if name in globals() and globals()[name] is not None:\n",
    "            available_models.append((name, globals()[name]))\n",
    "    \n",
    "    if not available_models:\n",
    "        print(\"❌ Koi model nahi mila!\")\n",
    "        print(\"Pehle apna model load/train karo\")\n",
    "    elif 'X_test' not in globals() or 'Y_test' not in globals():\n",
    "        print(\"❌ Test data nahi mila!\")\n",
    "        print(\"X_test aur Y_test load karo\")\n",
    "    else:\n",
    "        # Best model use karo\n",
    "        model_name, model = available_models[0]\n",
    "        print(f\"✅ Using model: {model_name}\")\n",
    "        print(f\"✅ Test data: {len(X_test)} images available\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"🎯 EK RANDOM IMAGE TEST\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Sirf ek test\n",
    "        simple_prediction_test(model, X_test, Y_test)\n",
    "        \n",
    "        # Agar aur test karna hai to uncomment karo\n",
    "        # quick_test_multiple_times(model, X_test, Y_test, num_tests=3)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    print(\"\\nSetup check karo:\")\n",
    "    print(\"1. Model trained hai?\")\n",
    "    print(\"2. X_test, Y_test loaded hai?\")\n",
    "\n",
    "print(\"\\n💡 Agar aur test karna hai to run karo:\")\n",
    "print(\"simple_prediction_test(your_model, X_test, Y_test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b023ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
