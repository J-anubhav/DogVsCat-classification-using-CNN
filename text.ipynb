{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d11369a",
   "metadata": {},
   "source": [
    "# New model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845eaafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, \n",
    "                                   Dropout, BatchNormalization, GlobalAveragePooling2D)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263eb4b",
   "metadata": {},
   "source": [
    "## Load and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbebdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load data with improved preprocessing\"\"\"\n",
    "    try:\n",
    "        X_train = np.loadtxt('input.csv', delimiter=',')\n",
    "        X_test = np.loadtxt('input_test.csv', delimiter=',')\n",
    "        Y_train = np.loadtxt('labels.csv', delimiter=',')\n",
    "        Y_test = np.loadtxt('labels_test.csv', delimiter=',')\n",
    "    except ValueError:\n",
    "        import pandas as pd\n",
    "        X_train = pd.read_csv('input.csv').to_numpy()\n",
    "        X_test = pd.read_csv('input_test.csv').to_numpy()\n",
    "        Y_train = pd.read_csv('labels.csv').to_numpy()\n",
    "        Y_test = pd.read_csv('labels_test.csv').to_numpy()\n",
    "    \n",
    "    # Reshape data\n",
    "    X_train = X_train.reshape(-1, 100, 100, 3)\n",
    "    X_test = X_test.reshape(-1, 100, 100, 3)\n",
    "    Y_train = Y_train.reshape(-1, 1)\n",
    "    Y_test = Y_test.reshape(-1, 1)\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Per-channel normalization \n",
    "    # Compute mean and std per channel on training data\n",
    "    train_mean = np.mean(X_train, axis=(0, 1, 2))\n",
    "    train_std = np.std(X_train, axis=(0, 1, 2))\n",
    "    \n",
    "    # Apply normalization\n",
    "    X_train = (X_train - train_mean) / (train_std + 1e-7)\n",
    "    X_test = (X_test - train_mean) / (train_std + 1e-7)\n",
    "    \n",
    "    print(f\"Training data shape: {X_train.shape}\")\n",
    "    print(f\"Test data shape: {X_test.shape}\")\n",
    "    print(f\"Training labels distribution: {np.bincount(Y_train.astype(int).flatten())}\")\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d8e8e",
   "metadata": {},
   "source": [
    "# data augmentatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b6d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators(X_train, Y_train, X_test, Y_test):\n",
    "    \"\"\"Create data generators with more aggressive augmentation\"\"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.3,\n",
    "        shear_range=0.2,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # No augmentation for validation data\n",
    "    val_datagen = ImageDataGenerator()\n",
    "    \n",
    "    train_generator = train_datagen.flow(X_train, Y_train, batch_size=32)\n",
    "    val_generator = val_datagen.flow(X_test, Y_test, batch_size=32, shuffle=False)\n",
    "    \n",
    "    return train_generator, val_generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472e3f9",
   "metadata": {},
   "source": [
    "# CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89fbc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_improved_model():\n",
    "    \"\"\"Create an improved CNN model with better architecture\"\"\"\n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Global Average Pooling instead of Flatten\n",
    "        GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Dense layers\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba439f73",
   "metadata": {},
   "source": [
    "# Transfer learning model (VGG16-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608f81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_learning_model():\n",
    "    \"\"\"Create a transfer learning model using VGG16\"\"\"\n",
    "    from tensorflow.keras.applications import VGG16\n",
    "    from tensorflow.keras.models import Model\n",
    "    \n",
    "    # Load pre-trained VGG16 model\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Add custom classifier\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1208d97c",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b748c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, val_generator, model_name=\"enhanced_model\"):\n",
    "    \"\"\"Train the model with advanced callbacks\"\"\"\n",
    "    \n",
    "    # Compile with optimized parameters\n",
    "    optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Advanced callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            f'{model_name}_best.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=100,  # More epochs with early stopping\n",
    "        validation_data=val_generator,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bce0c3",
   "metadata": {},
   "source": [
    "# Evaluation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2362f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_visualize(model, X_test, Y_test):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(y_pred.flatten() == Y_test.flatten())\n",
    "    print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(Y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Dog', 'Cat'], yticklabels=['Dog', 'Cat'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix - Enhanced Model')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(Y_test, y_pred, target_names=['Dog', 'Cat']))\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581508c7",
   "metadata": {},
   "source": [
    "# Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10866da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_prediction(models, X_test):\n",
    "    \"\"\"Create ensemble predictions from multiple models\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        pred = model.predict(X_test)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    return (ensemble_pred > 0.5).astype(int)\n",
    "\n",
    "# Main execution function\n",
    "def main():\n",
    "    \"\"\"Main function to run the entire pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"ENHANCED DOG VS CAT CLASSIFICATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Step 1: Load and preprocess data\n",
    "    print(\"\\n1. Loading and preprocessing data...\")\n",
    "    X_train, X_test, Y_train, Y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Step 2: Create data generators\n",
    "    print(\"\\n2. Creating data generators...\")\n",
    "    train_gen, val_gen = create_data_generators(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "    # Step 3: Train improved CNN model\n",
    "    print(\"\\n3. Training improved CNN model...\")\n",
    "    improved_model = create_improved_model()\n",
    "    print(f\"Model parameters: {improved_model.count_params():,}\")\n",
    "    \n",
    "    history1 = train_model(improved_model, train_gen, val_gen, \"improved_cnn\")\n",
    "    acc1 = evaluate_and_visualize(improved_model, X_test, Y_test)\n",
    "    \n",
    "    # Step 4: Train transfer learning model\n",
    "    print(\"\\n4. Training transfer learning model...\")\n",
    "    transfer_model = create_transfer_learning_model()\n",
    "    print(f\"Transfer model parameters: {transfer_model.count_params():,}\")\n",
    "    \n",
    "    # Recreate generators for transfer learning\n",
    "    train_gen2, val_gen2 = create_data_generators(X_train, Y_train, X_test, Y_test)\n",
    "    history2 = train_model(transfer_model, train_gen2, val_gen2, \"transfer_learning\")\n",
    "    acc2 = evaluate_and_visualize(transfer_model, X_test, Y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3857a4",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "974254d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_prediction(models, X_test):\n",
    "    \"\"\"Create ensemble predictions from multiple models\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        pred = model.predict(X_test)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    return (ensemble_pred > 0.5).astype(int)\n",
    "\n",
    "# Main execution function\n",
    "def main():\n",
    "    \"\"\"Main function to run the entire pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"ENHANCED DOG VS CAT CLASSIFICATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Step 1: Load and preprocess data\n",
    "    print(\"\\n1. Loading and preprocessing data...\")\n",
    "    X_train, X_test, Y_train, Y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Step 2: Create data generators\n",
    "    print(\"\\n2. Creating data generators...\")\n",
    "    train_gen, val_gen = create_data_generators(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "    # Step 3: Train improved CNN model\n",
    "    print(\"\\n3. Training improved CNN model...\")\n",
    "    improved_model = create_improved_model()\n",
    "    print(f\"Model parameters: {improved_model.count_params():,}\")\n",
    "    \n",
    "    history1 = train_model(improved_model, train_gen, val_gen, \"improved_cnn\")\n",
    "    acc1 = evaluate_and_visualize(improved_model, X_test, Y_test)\n",
    "    \n",
    "    # Step 4: Train transfer learning model\n",
    "    print(\"\\n4. Training transfer learning model...\")\n",
    "    transfer_model = create_transfer_learning_model()\n",
    "    print(f\"Transfer model parameters: {transfer_model.count_params():,}\")\n",
    "    \n",
    "    # Recreate generators for transfer learning\n",
    "    train_gen2, val_gen2 = create_data_generators(X_train, Y_train, X_test, Y_test)\n",
    "    history2 = train_model(transfer_model, train_gen2, val_gen2, \"transfer_learning\")\n",
    "    acc2 = evaluate_and_visualize(transfer_model, X_test, Y_test)\n",
    "    \n",
    "    # Step 5: Ensemble prediction\n",
    "    print(\"\\n5. Creating ensemble prediction...\")\n",
    "    ensemble_pred = create_ensemble_prediction([improved_model, transfer_model], X_test)\n",
    "    ensemble_acc = np.mean(ensemble_pred.flatten() == Y_test.flatten())\n",
    "    print(f\"Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
    "    \n",
    "    # Final comparison\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL RESULTS COMPARISON:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Improved CNN Accuracy: {acc1:.4f}\")\n",
    "    print(f\"Transfer Learning Accuracy: {acc2:.4f}\")\n",
    "    print(f\"Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return improved_model, transfer_model, ensemble_acc\n",
    "\n",
    "# Additional utility functions\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_prediction_examples(model, X_test, Y_test, num_examples=8):\n",
    "    \"\"\"Show prediction examples\"\"\"\n",
    "    indices = np.random.choice(len(X_test), num_examples, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        \n",
    "        # Denormalize image for display (if normalized)\n",
    "        img = X_test[idx]\n",
    "        if img.min() < 0:  # If normalized\n",
    "            img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        \n",
    "        pred_prob = model.predict(np.expand_dims(X_test[idx], axis=0))[0][0]\n",
    "        pred_class = \"Cat\" if pred_prob > 0.5 else \"Dog\"\n",
    "        true_class = \"Cat\" if Y_test[idx][0] > 0.5 else \"Dog\"\n",
    "        \n",
    "        color = 'green' if pred_class == true_class else 'red'\n",
    "        plt.title(f'True: {true_class}\\nPred: {pred_class} ({pred_prob:.2f})', \n",
    "                 color=color)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad69ea25",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84d1b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ENHANCED DOG VS CAT CLASSIFICATION\n",
      "==================================================\n",
      "\n",
      "1. Loading and preprocessing data...\n",
      "Training data shape: (2000, 100, 100, 3)\n",
      "Test data shape: (400, 100, 100, 3)\n",
      "Training labels distribution: [1000 1000]\n",
      "\n",
      "2. Creating data generators...\n",
      "\n",
      "3. Training improved CNN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\DogVsCat-classification-using-CNN\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 849,313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\DogVsCat-classification-using-CNN\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.5129 - loss: 1.1007\n",
      "Epoch 1: val_accuracy improved from None to 0.56000, saving model to improved_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 245ms/step - accuracy: 0.5010 - loss: 1.0985 - val_accuracy: 0.5600 - val_loss: 0.6893 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.5312 - loss: 0.9411\n",
      "Epoch 2: val_accuracy did not improve from 0.56000\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 242ms/step - accuracy: 0.5220 - loss: 0.9261 - val_accuracy: 0.5100 - val_loss: 0.7063 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.5429 - loss: 0.9153\n",
      "Epoch 3: val_accuracy did not improve from 0.56000\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 231ms/step - accuracy: 0.5410 - loss: 0.8696 - val_accuracy: 0.4950 - val_loss: 0.8943 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.5551 - loss: 0.8142\n",
      "Epoch 4: val_accuracy did not improve from 0.56000\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 231ms/step - accuracy: 0.5505 - loss: 0.8164 - val_accuracy: 0.5350 - val_loss: 0.6909 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.5653 - loss: 0.8157\n",
      "Epoch 5: val_accuracy did not improve from 0.56000\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 230ms/step - accuracy: 0.5705 - loss: 0.7862 - val_accuracy: 0.5425 - val_loss: 0.7158 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.5739 - loss: 0.7422\n",
      "Epoch 6: val_accuracy improved from 0.56000 to 0.57750, saving model to improved_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 235ms/step - accuracy: 0.5800 - loss: 0.7309 - val_accuracy: 0.5775 - val_loss: 0.6609 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.5710 - loss: 0.7263\n",
      "Epoch 7: val_accuracy did not improve from 0.57750\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 235ms/step - accuracy: 0.5810 - loss: 0.7236 - val_accuracy: 0.5750 - val_loss: 0.7317 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.6063 - loss: 0.7066\n",
      "Epoch 8: val_accuracy improved from 0.57750 to 0.60750, saving model to improved_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 233ms/step - accuracy: 0.5930 - loss: 0.6993 - val_accuracy: 0.6075 - val_loss: 0.6607 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6184 - loss: 0.6427\n",
      "Epoch 9: val_accuracy did not improve from 0.60750\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 231ms/step - accuracy: 0.6125 - loss: 0.6665 - val_accuracy: 0.5875 - val_loss: 0.7125 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6078 - loss: 0.6725\n",
      "Epoch 10: val_accuracy improved from 0.60750 to 0.61250, saving model to improved_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 238ms/step - accuracy: 0.6210 - loss: 0.6635 - val_accuracy: 0.6125 - val_loss: 0.6439 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6090 - loss: 0.6711\n",
      "Epoch 11: val_accuracy improved from 0.61250 to 0.63000, saving model to improved_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 234ms/step - accuracy: 0.6110 - loss: 0.6706 - val_accuracy: 0.6300 - val_loss: 0.6317 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.6340 - loss: 0.6786\n",
      "Epoch 12: val_accuracy did not improve from 0.63000\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 237ms/step - accuracy: 0.6395 - loss: 0.6582 - val_accuracy: 0.5850 - val_loss: 0.6815 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6354 - loss: 0.6425\n",
      "Epoch 13: val_accuracy improved from 0.63000 to 0.63250, saving model to improved_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 235ms/step - accuracy: 0.6325 - loss: 0.6451 - val_accuracy: 0.6325 - val_loss: 0.6258 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.6171 - loss: 0.6528\n",
      "Epoch 14: val_accuracy improved from 0.63250 to 0.67000, saving model to improved_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 246ms/step - accuracy: 0.6315 - loss: 0.6431 - val_accuracy: 0.6700 - val_loss: 0.6079 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6520 - loss: 0.6355\n",
      "Epoch 15: val_accuracy did not improve from 0.67000\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 239ms/step - accuracy: 0.6485 - loss: 0.6351 - val_accuracy: 0.6050 - val_loss: 0.6643 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6386 - loss: 0.6367\n",
      "Epoch 16: val_accuracy improved from 0.67000 to 0.70250, saving model to improved_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 242ms/step - accuracy: 0.6465 - loss: 0.6458 - val_accuracy: 0.7025 - val_loss: 0.5862 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6214 - loss: 0.6458\n",
      "Epoch 17: val_accuracy did not improve from 0.70250\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 233ms/step - accuracy: 0.6235 - loss: 0.6413 - val_accuracy: 0.6325 - val_loss: 0.6397 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6498 - loss: 0.6221\n",
      "Epoch 18: val_accuracy did not improve from 0.70250\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 231ms/step - accuracy: 0.6370 - loss: 0.6379 - val_accuracy: 0.5800 - val_loss: 0.6557 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6475 - loss: 0.6291\n",
      "Epoch 19: val_accuracy did not improve from 0.70250\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 228ms/step - accuracy: 0.6485 - loss: 0.6311 - val_accuracy: 0.6400 - val_loss: 0.6154 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6687 - loss: 0.6059\n",
      "Epoch 20: val_accuracy did not improve from 0.70250\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 229ms/step - accuracy: 0.6520 - loss: 0.6277 - val_accuracy: 0.6450 - val_loss: 0.6336 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.6413 - loss: 0.6334\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.70250\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 230ms/step - accuracy: 0.6535 - loss: 0.6228 - val_accuracy: 0.6550 - val_loss: 0.6181 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6654 - loss: 0.5989\n",
      "Epoch 22: val_accuracy did not improve from 0.70250\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 233ms/step - accuracy: 0.6735 - loss: 0.6099 - val_accuracy: 0.6675 - val_loss: 0.6129 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6676 - loss: 0.5998\n",
      "Epoch 23: val_accuracy did not improve from 0.70250\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 232ms/step - accuracy: 0.6670 - loss: 0.6057 - val_accuracy: 0.6775 - val_loss: 0.5822 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6578 - loss: 0.6000\n",
      "Epoch 24: val_accuracy did not improve from 0.70250\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 234ms/step - accuracy: 0.6830 - loss: 0.5917 - val_accuracy: 0.6475 - val_loss: 0.6002 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.6749 - loss: 0.5913\n",
      "Epoch 25: val_accuracy improved from 0.70250 to 0.74000, saving model to improved_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 233ms/step - accuracy: 0.6845 - loss: 0.5914 - val_accuracy: 0.7400 - val_loss: 0.5311 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6739 - loss: 0.5972\n",
      "Epoch 26: val_accuracy improved from 0.74000 to 0.75500, saving model to improved_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 238ms/step - accuracy: 0.6815 - loss: 0.5928 - val_accuracy: 0.7550 - val_loss: 0.5317 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.6805 - loss: 0.6005\n",
      "Epoch 27: val_accuracy did not improve from 0.75500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 236ms/step - accuracy: 0.6875 - loss: 0.5909 - val_accuracy: 0.6400 - val_loss: 0.6162 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6871 - loss: 0.5887\n",
      "Epoch 28: val_accuracy did not improve from 0.75500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 229ms/step - accuracy: 0.6770 - loss: 0.5945 - val_accuracy: 0.6875 - val_loss: 0.5793 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.7063 - loss: 0.5713\n",
      "Epoch 29: val_accuracy did not improve from 0.75500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 229ms/step - accuracy: 0.6980 - loss: 0.5788 - val_accuracy: 0.6475 - val_loss: 0.6578 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.7054 - loss: 0.5862\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.75500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 232ms/step - accuracy: 0.7035 - loss: 0.5870 - val_accuracy: 0.7175 - val_loss: 0.5602 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.7010 - loss: 0.5824\n",
      "Epoch 31: val_accuracy did not improve from 0.75500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 228ms/step - accuracy: 0.7070 - loss: 0.5784 - val_accuracy: 0.6675 - val_loss: 0.6076 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7110 - loss: 0.5565\n",
      "Epoch 32: val_accuracy did not improve from 0.75500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 232ms/step - accuracy: 0.7140 - loss: 0.5573 - val_accuracy: 0.6750 - val_loss: 0.6033 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.7135 - loss: 0.5739\n",
      "Epoch 33: val_accuracy did not improve from 0.75500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 232ms/step - accuracy: 0.7145 - loss: 0.5621 - val_accuracy: 0.6950 - val_loss: 0.6134 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7079 - loss: 0.5604\n",
      "Epoch 34: val_accuracy did not improve from 0.75500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 229ms/step - accuracy: 0.7200 - loss: 0.5412 - val_accuracy: 0.6850 - val_loss: 0.5592 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7329 - loss: 0.5456\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.75500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 230ms/step - accuracy: 0.7270 - loss: 0.5530 - val_accuracy: 0.7000 - val_loss: 0.5529 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.7189 - loss: 0.5521\n",
      "Epoch 36: val_accuracy did not improve from 0.75500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 232ms/step - accuracy: 0.7210 - loss: 0.5529 - val_accuracy: 0.7475 - val_loss: 0.5065 - learning_rate: 1.2500e-04\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n",
      "Final Test Accuracy: 0.7550\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAARf1JREFUeJzt3Qd4VNX29/GVkAIGCEWpl95BpEsR6VJEiqKIFwUBQZSOoKAgimjEAkgRbIAoetWLYgcpKipFOohIkSoYQCkxgQQI8z5r33fmP5OdYIKZzCTn+7nPuWTOOTOzp8RZ+e0yIS6XyyUAAACAl1DvCwAAAICiSAQAAICFIhEAAAAWikQAAABYKBIBAABgoUgEAACAhSIRAAAAFopEAAAAWCgSAQAAYKFIhOPs2bNH2rZtK9HR0RISEiKLFy/O1Ns/cOCAud358+dn6u1mZy1atDBbTuB+fV944QXJqe69914pW7asBCv93dLXQF+LjHriiSfMdQH8PYpEBMSvv/4q999/v5QvX15y584t+fPnlxtuuEFeeuklOXfunF/vu3fv3rJ9+3Z5+umn5a233pL69etLTvpw1w9AfT5Tex61QNbjV1rkHD161HzIbtmyRbILLXbcjznl1r59+0A3L1vTwl+fx0qVKqV6fNmyZZ7n+r///W+Wtw/APxP2D68PZNjnn38ud9xxh0RGRkqvXr3k2muvlfPnz8v3338vo0ePlh07dsirr77ql/vWwmnNmjXy2GOPyeDBg/1yH2XKlDH3Ex4eLoEQFhYmZ8+elU8//VS6d+/uc2zhwoWmKE9MTLyi29Yi8cknnzSFV+3atdN9va+++koCSdv60EMPWftLlCgRkPbkJPp+2rt3r/z4449y/fXXZ+r7DUBgUSQiS+3fv1969OhhCqmVK1dK8eLFPccGDRpkPmy0iPSXEydOmH8LFCjgt/vQ1EQ/GANFi29NZd99912rSHznnXekY8eOsmjRoixpixarV111lUREREgglSxZUu6+++6AtiGnqlChgly8eNG837yLRC0MP/rooyx9vwHIXHQ3I0s999xzEh8fL2+88YZPgehWsWJFGTZsmOeyfvg89dRT5oNIix9NsB599FFJSkryuZ7uv+WWW0waqR9UWqRpV/aCBQs852g3qRanShNLLebc467SGoOV2vgl7UJr2rSpKTTz5s0rVapUMW36uzGJWhTfeOONEhUVZa7bpUsX2blzZ6r3p8WytknP07GTffr0MQVXev373/+WL7/8Uk6fPu3Zt379etPdrMdSOnnypIwaNUpq1qxpHpN2V3fo0EG2bt3qOeebb76RBg0amJ+1Pe5uRPfj1K5HTYU3btwozZo1M8Wh+3lJOSZRu/z1NUr5+Nu1aycFCxY0iWVW0+dbH/uRI0eka9eu5udrrrnGPC/JycmpXkcTb/d7U58bfY69bdu2zdyue1hFsWLFpG/fvvLnn3/+o9f97bffNu9zfY71+dLnO2Vaq6+/+/2WL18+U6xpSp+SjsnV103bp/9qYZdRd911l7z33nty6dIlzz5NsrXtKf9Qcdu8ebN5j+l7TZ/r1q1by9q1a63ztM2tWrWSPHnyyL/+9S+ZNGmSz/1cyWMGkD4UichS+sGhH5hNmjRJ1/n33XefPP7441K3bl2ZOnWqNG/eXGJiYkwamZJ+wN5+++1y0003yYsvvmg+PPUD1/0hcdttt5nbcH+o6XjEadOmZaj9eltajGqROnHiRHM/nTt3lh9++OGy11u+fLkpgI4fP24KgpEjR8rq1atN4pfa4Hv9YP3rr7/MY9WftRDTbt700seqRceHH37okyJWrVrVPJcp7du3zxQL+timTJliimgdt6nPt7tgq1atmnnMasCAAeb5000LFDctfvSDX7t39blt2bJlqu3TsadagGmx6C7AXnnlFVPozJgxI9O7gS9cuCB//PGHtaUct6lt0depcOHCZsymPn59jVMb/qDP5/PPP2/G1mrhoq+jPu96X95/UOhzq8WePi593/7nP/+Rm2++WVwu1xW97nr5nnvuMcMZ9PXQy6VKlTJ/hLjp66IFkhZfkydPlvHjx8vPP/9s/rjxfr/p892tWzfzXtH71OJY27phw4YMPb/6h8fvv/9u/pDwfn608CtSpEiqv0dazOkfIQ8//LBpn/Yy6B8S69at85wXGxtr3kM6BnbMmDEyfPhw84efvn9SSu9jBpABLiCLnDlzRj8VXV26dEnX+Vu2bDHn33fffT77R40aZfavXLnSs69MmTJm36pVqzz7jh8/7oqMjHQ99NBDnn379+835z3//PM+t9m7d29zGylNmDDBnO82depUc/nEiRNpttt9H/PmzfPsq127tqtIkSKuP//807Nv69atrtDQUFevXr2s++vbt6/Pbd56662uwoULp3mf3o8jKirK/Hz77be7WrdubX5OTk52FStWzPXkk0+m+hwkJiaac1I+Dn3+Jk6c6Nm3fv1667G5NW/e3BybM2dOqsd087Z06VJz/qRJk1z79u1z5c2b19W1a1dXZnO/N1LbYmJifJ473ef9eFWdOnVc9erV81x2P3/6epw8edKz/+OPPzb7P/30U8++s2fPWu159913rfdqel/3PXv2mPeM7k/5el26dMn8+9dff7kKFCjg6t+/v8/x2NhYV3R0tM9+fV8WL17cdfr0ac++r776yrQltd+HlPQ1rVGjhvm5fv36rn79+pmfT5065YqIiHC9+eabrq+//trc3gcffOC5nr7OevzXX3/17Dt69KgrX758rmbNmnn2DR8+3Fx33bp1Pr/X+jh0v74WGX3MKX+nAaSNJBFZJi4uzvyr3UDp8cUXX5h/NXXz5p6AkHLsYvXq1U064aZJlXYFa5KTWdxjGT/++OM0u7xS0oRFkxBNNQsVKuTZf91115nU0/04vQ0cONDnsj4uTencz2F60x1NdjSN0ZRJ/02tq1lpd2loaKgnTdP7cnelb9q0Kd33qbejSVR66DJEmsJpGqYJnHZ3aproDw0bNjSpXspNE+X0PPepvYfuvPNOk1Z7n6e8z9UuUu8xeppeNmrUyFxO7Xn9u9dd015932m67n693NzDIvRx6TADfWzeqWmuXLnM8/D111/7vC81zdWubTd9T+rvUkbpe0uTa52EpjOZ9f5uvfVW6zx9f2mCqaml9iq46fATvQ0dMuJ+vPq7oc+X91hH/b3u2bOnz22m9zEDyBgmriDL6Ngjpd1p6XHw4EHzQajjFL3puC4t1vS4t9KlS1u3oR/ip06dksyihcHrr79uusG1+0u707TA0W7ulB/a3o9DacGVknbhLl26VBISEsw4qrQei7sY0cfifh7/jnZpakGuY8W0GNAxc/pcptb1poWHduG9/PLLptvPewyedr1mZIJIRiapaJeuFtzaPu2eTK1rMrXJR97t02JWt8u5+uqrpU2bNn9721qoahGSnvfQ5V4j77Ge2h2sXcw61MDbmTNnMnSb+rrr0lH6PrtcEafjTpWO40uN+/3jfl+mtnxNRv84UNqVruM3dVygzmrWoQup/UGor5+OVUzr90Hfi4cPH5YaNWqYNmqRl1r7ruQxA8gYikRkGf0PtY41++mnnzJ0vfQufKupQWpSG/uV3vtIOWFBk6FVq1aZZEKTzCVLlpgiTD+cNB1Jqw0Z9U8ei3eqpwXsm2++adItHQuZlmeeecaM4dJJFTpRSBNPLUZ0DFh6E9OUyVl66OQFd/GkYyBTS/ZS0mLX+w+ECRMmXPaxZURGXr/0vEY6rlDHnuoYTx2nqcWsPp+6PmNqz2tmvO7u29UxevoHVWpLJPmDJoE6plDHcOoY3ayc0RyoxwzkdPzmIEtpuqCTAHStwsaNG1/2XJ2JrP/x15RAEwa3Y8eOma4l90zlzKCJjfdMYLeUaaXS4kkTRN10kocWWLruohaOqaVV7nbu2rXLOvbLL7+YlMs7RcxM2n03d+5c0+bUJvu4afegThDQWefe9DnR9rll5jdVaHqqXdOaiulEJp35rt2T7hnUadGUynvCiXeXZTDR9G/FihUmSdTu4ZSp15XQmdT6O6ETMtJap1LPUZrKXi49db8vU2tPau/V9L7fNGXXpF+T7NRoUquzstP6fdD3qk7EcbcxPe1L72MGkDGMSUSW0pmMWhDpB4kWeylpd5p75qL7QyblDGQtzJTOZMws+iGj3X+6ZImbjtlKuRyIdh+m5P6wTrksj3fCoudoouddiGqiquljWh+mmUELP00GZ86cmWrC4p1gpUyrPvjgA7McjDd3MZtaQZ1RjzzyiBw6dMg8L/qa6hJEOj4urefRTWeEayHg3oK1SHSngimf14zOqPem4/i0iNJxnCmTSPf96OxsTe31jxfvmdYp1wr1fl96d33r+D4tQq+EDrvQZFeHLaQ17ECfFx2PqsMMvIc+6H8PdMiBzkZ2dw/r74Yui6MLdXu3X/9Q8JbexwwgY0gSkaW0GNMPAh3bp+mg9zeuaLecFiY6wUPVqlXLFA2aPGpRosuR6IeFfqjph2Vay6tcCU3ZtGjRJGvo0KFmzNTs2bOlcuXKPmOz9MNZu5u1QNWUQ7tK9QNR12/TD7e06FIpujSMpqf9+vUzSZguiaITBjKrqzQ1WlCMGzcuXQmvPjZN9jTV065f/SBOWYDp66cp0Zw5c8x4My0adcxYuXLlMtQunUijz5sWFO4leebNm2e6K7XbW1PFzKTFrq4tmJJ2/+p7yR+0aNHlgfSxaOGi4zX1jwId83mldEypptZa+OukFh1OoMMKdH1GHcqhy9jo/ep7V5fJ0edW39ua3mlBrkMktMjWPxqUnq/vZX3v6lAD/SNI35c6HlDXM82o9L6fdckg93qjDz74oOkO1klL+geC92uvf1RqF7J2z+v6qfp+0/8e6O+e9x90GXnMADLgMjOfAb/ZvXu3WZaibNmyZikMXfrihhtucM2YMcMsx+J24cIFs2xLuXLlXOHh4a5SpUq5xo4d63OO0uU6Onbs+LdLr6S1BI576Y9rr73WtKdKlSqut99+21ouY8WKFWYJnxIlSpjz9N+77rrLPJ6U95FymZjly5ebx5gnTx5X/vz5XZ06dXL9/PPPPue47y/lEjt6W95LfqRnCZy0pLUEji4VpMuhaPu0nWvWrEl16Rpd6qV69equsLAwn8fpvRxKSt63ExcXZ16vunXrmtfX24gRI8wSL3rfWbEEjvcyL2k9dynfA5d7D+l+Pd/tt99+M8vV6PIsuhTLHXfcYZZ6SXleRl/3uXPnmqV5dImiggULmud22bJlPufo0jPt2rUz95s7d25XhQoVXPfee69rw4YNPuctWrTIVa1aNXNb+rp++OGHaS4JldLlXnPvdqRcAkdt2rTJtE+XPrrqqqtcLVu2dK1evdq6/rZt28z96GMoWbKk66mnnnK98cYbqT4v6XnMLIEDpF+I/l9GikoAAADkfIxJBAAAgIUiEQAAABaKRAAAAFgoEgEAAGChSAQAAICFIhEAAAAWikQAAAA44xtXKo76MtBNAOAn8+9vFOgmAPCTppUKBuy+89QZ7LfbPrc5e37jD0kiAAAAnJEkAgAAZEgIuVlKFIkAAAAhIYFuQdChbAYAAICFJBEAAIDuZgvPCAAAACwkiQAAAIxJtJAkAgAAwEKSCAAAwJhEC88IAAAALCSJAAAAjEm0UCQCAADQ3WzhGQEAAICFJBEAAIDuZgtJIgAAACwkiQAAAIxJtPCMAAAAwEKSCAAAwJhEC0kiAAAALCSJAAAAjEm0UCQCAADQ3WyhbAYAAICFJBEAAIDuZgvPCAAAACwkiQAAACSJFp4RAACAILJq1Srp1KmTlChRQkJCQmTx4sXWOTt37pTOnTtLdHS0REVFSYMGDeTQoUOe44mJiTJo0CApXLiw5M2bV7p16ybHjh3LUDsoEgEAAEJD/LdlUEJCgtSqVUtmzZqV6vFff/1VmjZtKlWrVpVvvvlGtm3bJuPHj5fcuXN7zhkxYoR8+umn8sEHH8i3334rR48eldtuuy1D7aC7GQAAIIh06NDBbGl57LHH5Oabb5bnnnvOs69ChQqen8+cOSNvvPGGvPPOO9KqVSuzb968eVKtWjVZu3atNGrUKF3tIEkEAADQMYl+2pKSkiQuLs5n031X4tKlS/L5559L5cqVpV27dlKkSBFp2LChT5f0xo0b5cKFC9KmTRvPPk0dS5cuLWvWrEn3fVEkAgAA6GLaftpiYmLM2EHvTfddiePHj0t8fLw8++yz0r59e/nqq6/k1ltvNV3J2q2sYmNjJSIiQgoUKOBz3aJFi5pj6UV3MwAAgB+NHTtWRo4c6bMvMjLyipNE1aVLFzPuUNWuXVtWr14tc+bMkebNm0tmoUgEAADw4xI4kZGRV1wUpnT11VdLWFiYVK9e3We/jjf8/vvvzc/FihWT8+fPy+nTp33SRJ3drMfSi+5mAACAbCIiIsIsd7Nr1y6f/bt375YyZcqYn+vVqyfh4eGyYsUKz3E9X5fIady4cbrviyQRAABAxw8Gifj4eNm7d6/n8v79+2XLli1SqFAhM/lk9OjRcuedd0qzZs2kZcuWsmTJErPcjS6Ho3TMY79+/UwXt14nf/78MmTIEFMgpndms6JIBAAACCIbNmwwxZ+bezxj7969Zf78+Waiio4/1MkvQ4cOlSpVqsiiRYvM2oluU6dOldDQULOIts6k1pnQL7/8cobaEeJyuVySw1Qc9WWgmwDAT+bfn/6/ggFkL00rFQzYfedp+7zfbvvcV6MlO2JMIgAAACx0NwMAAATRmMRgQZEIAADgxyVwsiueEQAAAFhIEgEAAOhutpAkAgAAwEKSCAAAwJhEC88IAAAALCSJAAAAjEm0kCQCAADAQpIIAADAmEQLRSIAAABFooVnBAAAABaSRAAAACauWEgSAQAAYCFJBAAAYEyihWcEAAAAFpJEAAAAxiRaSBIBAABgIUkEAABgTKKFIhEAAIDuZgtlMwAAACwkiQAAwPFCSBItJIkAAACwkCQCAADHI0m0kSQCAADAQpIIAABAkGghSQQAAICFJBEAADgeYxJtFIkAAMDxKBJtdDcDAADAQpIIAAAcjyTRRpIIAAAAC0kiAABwPJJEG0kiAAAALCSJAAAABIkWkkQAAABYSBIBAIDjMSbRRpIIAAAAC0kiAABwPJJEG0UiAABwPIpEG93NAAAAsJAkAgAAxyNJtJEkAgAAwEKSCAAAQJBoIUkEAACAhSQRAAA4HmMSbSSJAAAAsJAkAgAAxyNJtFEkAgAAx6NItNHdDAAAAAtJIgAAAEGihSQRAAAAFpJEAADgeIxJtJEkAgAAwEKSCAAAHI8k0UaSCAAAEERWrVolnTp1khIlSpjidfHixWmeO3DgQHPOtGnTfPafPHlSevbsKfnz55cCBQpIv379JD4+PkPtoEgEAACOp4WWv7aMSkhIkFq1asmsWbMue95HH30ka9euNcVkSlog7tixQ5YtWyafffaZKTwHDBiQoXbQ3QwAABwvmLqbO3ToYLbLOXLkiAwZMkSWLl0qHTt29Dm2c+dOWbJkiaxfv17q169v9s2YMUNuvvlmeeGFF1ItKlNDkggAAOBHSUlJEhcX57Ppvit16dIlueeee2T06NFSo0YN6/iaNWtMF7O7QFRt2rSR0NBQWbduXbrvhyIRAAAgxH9bTEyMREdH+2y670pNnjxZwsLCZOjQoakej42NlSJFivjs0/MLFSpkjqUX3c0AAAB+NHbsWBk5cqTPvsjIyCu6rY0bN8pLL70kmzZt8nsXOUUiAABwPH8WXJGRkVdcFKb03XffyfHjx6V06dKefcnJyfLQQw+ZGc4HDhyQYsWKmXO8Xbx40cx41mPpRZEIAACQTdxzzz1mfKG3du3amf19+vQxlxs3biynT582qWO9evXMvpUrV5qxjA0bNkz3fVEkAgAAxwum2c3x8fGyd+9ez+X9+/fLli1bzJhCTRALFy7sc354eLhJCKtUqWIuV6tWTdq3by/9+/eXOXPmyIULF2Tw4MHSo0ePdM9sVkxcAQAACCIbNmyQOnXqmE3peEb9+fHHH0/3bSxcuFCqVq0qrVu3NkvfNG3aVF599dUMtYMkEQAAOF4wJYktWrQQl8uV7vN1HGJKmjq+8847/6gdFIkAAADBUyMGDbqbAQAAEJxJovazpxbz6r7cuXNLxYoV5d5775WWLVsGpH0AACBnC6bu5mARFEmizsDZt2+fREVFmUJQt7x588qvv/4qDRo0kN9//91M9/74448D3VQAAABHCIok8Y8//jCLQI4fP95n/6RJk+TgwYPy1VdfyYQJE+Spp56SLl26BKydAAAgZyJJDNIk8f3335e77rrL2q/r+egxpcd37doVgNYBAAA4T1AkiTrucPXq1WbsoTfdp8eUrhLu/hk5X4PyBaV/i/JSo2R+KRqdWwbO2yjLd/zfVwwNbVtROtYuLsUL5JYLF13y029nZMqS3bL10BnPOa/0qSvVSuSXwnkj5My5C7J6z5/y3Oe75HhcUoAeFYDUnPrjuPx3/izZvnGNnE9KkiLF/yV9h4+TspWqmeP9bmmU6vXu6DNY2ne7O4tbi5yKJDFIi8QhQ4bIwIEDzdfH6BhEtX79enn99dfl0UcfNZeXLl0qtWvXDnBLkVXyROSSnUfj5IMff5PZ99a1ju8/kSBPfvSzHP7zrOQOzyV9mpWV+f0bSOtnV8nJhPPmnLV7T8rsFfvk+F+JUjR/bhnbqarM7FVHus9cG4BHBCA1CfFxEvPwAKl6XT0Z/sRUyRddUI4dPSxX5c3nOWfKW5/7XGf7hjUyf/rTUu8GJjMCOb5IHDdunJQrV05mzpwpb731ltmnXy3z2muvyb///W9zWYvIBx54IMAtRVZZ9csfZkvLp5t/97n8zCe/SPeGpaRK8XyyZu+fZt+87/5vcdGjpxLllZX7TMEZFhoiFy+lf5FSAP7z5X/fkkJXF5W+w/9vTPo1xXy/Niy6oO9XkG1et0qq1Kwn1xQrmWXtRM5HkhikRaLq2bOn2dKSJ0+eLG0Pso/wXCFyZ6NSEnfugvxyNC7Vc6LzhEvnuiVk08FTFIhAENmy7ju5tm4jeTnmUdn902YpUPgaaXnzbdK8fddUzz9z6k/Zvv4H6Tsi/V9PBqQLNWLwFolKu5t37txpfq5Ro4bnOwsvJykpyWzeXBcvSEhYuN/aieDQsto1Mu3u2pInPJcc/ytJer+6Xk6dveBzzuiOVeSeG0rLVRFhsvnAKek/d2PA2gvAdiL2qHz9xYfStutd0rF7bzmwZ6e8++pUCQsPlxtad7TOX73iC4nMEyX1mrQISHsBJwmK2c3Hjx+XVq1amfGIQ4cONVu9evXMl1KfOHHisteNiYmR6Ohon+3Uj+9lWdsROGt/PSmdp/xgxhh+98sJmX5PbSmUN8LnnNe/3mfO6f3Kj5Lscsnzd10XsPYCsLlcl6RMhSrSrfcD5l9NEJu16yzffPFRqud/v/wzadSirYRHRGZ5W5Hzu5v9tWVXocEyceWvv/6SHTt2yMmTJ832008/SVxcnCkYL2fs2LFy5swZn63g9XdmWdsROOfOJ8vBP8/KlkOnZewHP0lysku6X/8vn3M0WTzwx1n5Yc+fMvztrdKyWhGpU6ZAwNoMwFd0waulROmyPvuKlyorJ08cs87d/dMWif3toDRry3q5gGO6m5csWSLLly+XatX+t9yBql69usyaNUvatm172etGRkaazRtdzc4UGhIiEWFp/93j/mPucucAyFqVql8nsb8d8tl37MhhKVykmHXud8s+kTIVq0qp8pWysIVwiuyc+PlLUHxa6hqI4eF2Yaf79Bic56qIXFKtRD6zqVKFrjI/67qIujzOQx0qS+3SBaREwdxmLcWY7jWlaHSkfLk11pxfq3S0GYuo19FzGlUsJNN61paDfyTI5gOnA/zoALjd1KWH7Nv1k3z+/nyz9M3ab5bKt0sWS6uO3XzOO3c2QTZ8v1Kate0csLYCThMUSaKORxw2bJi8++67UqLE/5Y+OHLkiIwYMcKMS4Tz1CwVLQsfaOi5/FiX/6XMi9b/JuMX7ZDyRaLk1vp1pFBUhJxKOC/bD5+RHi+vkz3H4j1d0W1rFpOhbSuZglMntuiSOi+/tVfOJ/OHBxAsylWuLoMemyyL3pwtn7w7V64pWlx69B8ujVq29znvx1XLdASjXN/88r1LwJUiSLSFuFyugK8HcvjwYencubMZk1iqVCnPvmuvvVY++eQT+de/fMeZ/Z2Ko770U0sBBNr8+1P/9g0A2V/TSgUDdt/+rB32vtBBsqOgSBK1MNy0aZOsWLHCswSOjk9s06ZNoJsGAAAcgDGJQVgk6pjD+fPny4cffigHDhwwL5J++4ouZaMhJy8aAADwN8qNIJu4okWgdjPfd999ZgxizZo1zSLaBw8elHvvvVduvfXWQDYPAADAsQKaJGqCuGrVKtPN3LKl7xe1r1y5Urp27SoLFiyQXr16BayNAAAg56PnMsiSRJ3N/Oijj1oFonvG85gxY2ThwoUBaRsAAICTBbRI3LZtm7Rv77vMgbcOHTrI1q1bs7RNAADAeTRI9NeWXQW0SNSv3ytatGiax/XYqVOnsrRNAAAACPCYxOTkZAkLS7sJuXLlkosXL2ZpmwAAgPOEhmbjyC8nFok6u1lnMaf87mW3pKSkLG8TAAAAAlwk9u7d+2/PYWYzAADwt+w8djBHFonz5s0L5N0DAAAYLIETZBNXAAAAEJwC/rV8AAAAgUaQaCNJBAAAgIUkEQAAOB5jEm0kiQAAALCQJAIAAMcjSbSRJAIAAMBCkggAAByPINFGkQgAAByP7mYb3c0AAACwkCQCAADHI0i0kSQCAADAQpIIAAAcjzGJNpJEAAAAWEgSAQCA4xEk2kgSAQAAYCFJBAAAjseYRBtJIgAAACwkiQAAwPEIEm0UiQAAwPHobrbR3QwAAAALSSIAAHA8gkQbSSIAAAAsJIkAAMDxGJNoI0kEAACAhSQRAAA4HkGijSQRAAAAFpJEAADgeIxJtJEkAgAAx9Ma0V9bRq1atUo6deokJUqUMMXr4sWLPccuXLggjzzyiNSsWVOioqLMOb169ZKjR4/63MbJkyelZ8+ekj9/filQoID069dP4uPjM9QOikQAAIAgkpCQILVq1ZJZs2ZZx86ePSubNm2S8ePHm38//PBD2bVrl3Tu3NnnPC0Qd+zYIcuWLZPPPvvMFJ4DBgzIUDvobgYAAI4XTN3NHTp0MFtqoqOjTeHnbebMmXL99dfLoUOHpHTp0rJz505ZsmSJrF+/XurXr2/OmTFjhtx8883ywgsvmPQxPUgSAQAA/CgpKUni4uJ8Nt2XWc6cOWOKXO1WVmvWrDE/uwtE1aZNGwkNDZV169al+3YpEgEAgONpkeWvLSYmxiSA3pvuywyJiYlmjOJdd91lxh+q2NhYKVKkiM95YWFhUqhQIXMsvehuBgAA8KOxY8fKyJEjffZFRkb+49vVSSzdu3cXl8sls2fPlsxGkQgAABzPn0MSIyMjM6UoTK1APHjwoKxcudKTIqpixYrJ8ePHfc6/ePGimfGsx9KL7mYAAIBs5ML/LxD37Nkjy5cvl8KFC/scb9y4sZw+fVo2btzo2aeF5KVLl6Rhw4bpvh+SRAAA4HjBNLs5Pj5e9u7d67m8f/9+2bJlixlTWLx4cbn99tvN8je6tE1ycrJnnKEej4iIkGrVqkn79u2lf//+MmfOHFNUDh48WHr06JHumc2KIhEAADheENWIsmHDBmnZsqXnsns8Y+/eveWJJ56QTz75xFyuXbu2z/W+/vpradGihfl54cKFpjBs3bq1mdXcrVs3mT59eobaQZEIAAAQRFq0aGEmo6TlcsfcNFV85513/lE7KBIBAIDjBVN3c7Bg4goAAAAsJIkAAMDxCBJtJIkAAACwkCQCAADHCyVKtJAkAgAAwEKSCAAAHI8g0UaRCAAAHI8lcGx0NwMAAMBCkggAABwvlCDRQpIIAAAAC0kiAABwPMYk2kgSAQAAYCFJBAAAjkeQaCNJBAAAgIUkEQAAOF6IECWmRJEIAAAcjyVwbHQ3AwAAwEKSCAAAHI8lcGwkiQAAALCQJAIAAMcjSLSRJAIAAMBCkggAABwvlCjRQpIIAAAAC0kiAABwPIJEG0UiAABwPJbAsdHdDAAAAAtJIgAAcDyCRBtJIgAAACwkiQAAwPFYAsdGkggAAAALSSIAAHA8ckQbSSIAAAAsJIkAAMDxWCfRRpEIAAAcL5Qa0UJ3MwAAACwkiQAAwPHobraRJAIAAMBCkggAAByPINFGkggAAAALSSIAAHA8xiTaSBIBAABgIUkEAACOxzqJNopEAADgeHQ32+huBgAAgIUkEQAAOB45oo0kEQAAAJlTJH733Xdy9913S+PGjeXIkSNm31tvvSXff//9ldwcAABAQIWGhPhtc0yRuGjRImnXrp3kyZNHNm/eLElJSWb/mTNn5JlnnvFHGwEAABDsReKkSZNkzpw58tprr0l4eLhn/w033CCbNm3K7PYBAAD4nQZ+/tocUyTu2rVLmjVrZu2Pjo6W06dPZ1a7AAAAkJ2KxGLFisnevXut/ToesXz58pnVLgAAgCxdJ9Ffm2OKxP79+8uwYcNk3bp15oEfPXpUFi5cKKNGjZIHHnjAP60EAABAcK+TOGbMGLl06ZK0bt1azp49a7qeIyMjTZE4ZMgQ/7QSAADAj7Jx4Bc8RaKmh4899piMHj3adDvHx8dL9erVJW/evP5pIQAAgJ9l56Vqgu4bVyIiIkxxCAAAgJwnw2MSW7ZsKa1atUpzAwAAyG6CaQmcVatWSadOnaREiRKmB3fx4sU+x10ulzz++ONSvHhxs251mzZtZM+ePT7nnDx5Unr27Cn58+eXAgUKSL9+/Uzvr1+LxNq1a0utWrU8m6aJ58+fN2sk1qxZM6M3BwAAAC8JCQmmxpo1a5ak5rnnnpPp06ebdat1InFUVJT5opPExETPOVog7tixQ5YtWyafffaZKTwHDBggfu1unjp1aqr7n3jiiQxXqAAAAMEgmJaq6dChg9lSoynitGnTZNy4cdKlSxezb8GCBVK0aFGTOPbo0UN27twpS5YskfXr10v9+vXNOTNmzJCbb75ZXnjhBZNQ+u27m1Oj3+U8d+7czLo5AACAHCEpKUni4uJ8NvfXGmfU/v37JTY21nQxe3+hScOGDWXNmjXmsv6rXczuAlHp+aGhoSZ59PvElZS0Qblz55Zg8NOzqVffALK/gg0GB7oJAPzk3OaZAbvvTEvNUhETEyNPPvmkz74JEyaYXtiM0gJRaXLoTS+7j+m/RYoU8TkeFhYmhQoV8pzjlyLxtttus2LP33//XTZs2CDjx4/P6M0BAADkaGPHjpWRI0f67NM1poNdhotEjTS9aXRZpUoVmThxorRt2zYz2wYAAJDtxyRGRkZmWlGoX4+sjh07ZmY3u+llnVzsPuf48eM+17t48aKZ8ey+fqYXicnJydKnTx8zi7lgwYIZuSoAAEDQCg2eeSuXVa5cOVPorVixwlMU6hhHHWvo/nrkxo0by+nTp2Xjxo1Sr149s2/lypXmG/N07KJfisRcuXKZtFBnzVAkAgAAZD5dLUa/1c57ssqWLVvMmMLSpUvL8OHDZdKkSVKpUiVTNOpwP52x3LVrV3N+tWrVpH379tK/f3+zTM6FCxdk8ODBZuZzemc2X1F387XXXiv79u0zjQIAAMgJgilJ3LBhg/nyEjf3eMbevXvL/Pnz5eGHHzZrKeq6h5oYNm3a1Cx54z2BeOHChaYwbN26tRka2K1bN7O2YkaEuHTmSQZoI3QA5lNPPWUiTF3A0Zuu7B1oiRcD3QIA/sLsZiDnCuTs5pGf/OK3257SuapkR+lOEnViykMPPWQWYlSdO3f2GeSptaZe1nGLAAAA2UkwLaad7YpEXd9n4MCB8vXXX/u3RQAAAMg+RaK7V7p58+b+bA8AAICjxyQGiwwtME4UCwAA4AwZmt1cuXLlvy0UdaFGAACA7IQc7B8WiTouMeU3rgAAAGR3oVSJ/6xI1EUYU35hNAAAABxcJDIeEQAA5FQZmqThEOl+TjK45jYAAACckCTql0IDAADkRHSY2khXAQAA8M8mrgAAAOREzG62kSQCAADAQpIIAAAcjyDRRpEIAAAcj+9uttHdDAAAAAtJIgAAcDwmrthIEgEAAGAhSQQAAI5HkGgjSQQAAICFJBEAADges5ttJIkAAACwkCQCAADHCxGixJQoEgEAgOPR3WyjuxkAAAAWkkQAAOB4JIk2kkQAAABYSBIBAIDjhbCatoUkEQAAABaSRAAA4HiMSbSRJAIAAMBCkggAAByPIYk2ikQAAOB4oVSJFrqbAQAAYCFJBAAAjsfEFRtJIgAAACwkiQAAwPEYkmgjSQQAAICFJBEAADheqBAlpkSSCAAAAAtJIgAAcDzGJNooEgEAgOOxBI6N7mYAAABYSBIBAIDj8bV8NpJEAAAAWEgSAQCA4xEk2kgSAQAAYCFJBAAAjseYRBtJIgAAACwkiQAAwPEIEm0UiQAAwPHoWrXxnAAAAMBCkggAABwvhP5mC0kiAAAALCSJAADA8cgRbSSJAAAAsFAkAgAAx9PFtP21ZURycrKMHz9eypUrJ3ny5JEKFSrIU089JS6Xy3OO/vz4449L8eLFzTlt2rSRPXv2SGajSAQAAAgSkydPltmzZ8vMmTNl586d5vJzzz0nM2bM8Jyjl6dPny5z5syRdevWSVRUlLRr104SExMztS2MSQQAAI4XLGMSV69eLV26dJGOHTuay2XLlpV3331XfvzxR0+KOG3aNBk3bpw5Ty1YsECKFi0qixcvlh49emRaW0gSAQCA42mvsL+2pKQkiYuL89l0X2qaNGkiK1askN27d5vLW7dule+//146dOhgLu/fv19iY2NNF7NbdHS0NGzYUNasWZOpzwlFIgAAgB/FxMSYQs57032pGTNmjEkDq1atKuHh4VKnTh0ZPny49OzZ0xzXAlFpcuhNL7uPZRa6mwEAgOP5czHtsWPHysiRI332RUZGpnru+++/LwsXLpR33nlHatSoIVu2bDFFYokSJaR3796SlSgSAQAA/CgyMjLNojCl0aNHe9JEVbNmTTl48KBJHrVILFasmNl/7NgxM7vZTS/Xrl07U9tNdzMAAHC8UD9uGXH27FkJDfW9Vq5cueTSpUvmZ10aRwtFHbfopmMcdZZz48aNJTORJAIAAASJTp06ydNPPy2lS5c23c2bN2+WKVOmSN++fT3d4tr9PGnSJKlUqZIpGnVdRe2O7tq1a6a2hSIRAAA4nj/HJGaEroeoRd+DDz4ox48fN8Xf/fffbxbPdnv44YclISFBBgwYIKdPn5amTZvKkiVLJHfu3JKZQlzeS3jnEIkXA90CAP5SsMHgQDcBgJ+c2zwzYPf9/pajfrvt7rVLSHZEkggAABwvOHLE4MLEFQAAAFhIEgEAgOMFy5jEYEKRCAAAHI+uVRvPCQAAACwkiQAAwPHobraRJAIAAMBCkggAAByPHNFGkggAAAALSSIAAHA8hiTaSBIBAABgIUkEAACOF8qoRAtFIgAAcDy6m210NwMAAMBCkggAABwvhO5mC0kiAAAALCSJAADA8RiTaCNJBAAAgIUkEQAAOB5L4NhIEgEAAGAhSQQAAI7HmEQbRSIAAHA8ikQb3c0AAACwkCQCAADHYzFtG0kiAAAALCSJAADA8UIJEi0kiQAAALCQJAIAAMdjTKKNJBEAAAAWkkQAAOB4rJNoo0gEAACOR3ezje5mAAAABF+ROHHiRDl79qy1/9y5c+YYAABAViyB468tuwp4kfjkk09KfHy8tV8LRz0GAAAAB45JdLlcEpLKaNGtW7dKoUKFAtImAADgLIxJDKIisWDBgqY41K1y5co+hWJycrJJFwcOHBio5gEAADhawIrEadOmmRSxb9++pls5OjracywiIkLKli0rjRs3DlTzEGTe/8878v5778rRI0fM5QoVK8n9DzwoTW9sbi7/9/335MsvPpOdP++QhIQE+W7NesmfP3+AWw0gNTfUrSAjerWRutVLS/FroqX7iFfl02+2+ZxTpVxRmTSsq9xYt6KEhYXKL/ti5a5Rr8vh2FPmeLl/XS3PjrhVGtcpL5HhYbJs9U4ZOfkDOX7yrwA9KmR3LIETREVi7969zb/lypWTJk2aSHh4eKCagmygSNFiMmzEKCldpoz54+LTjxfLsMGD5L1FH0nFipUkMfGcNLnhRrNNn/ZioJsL4DKi8kTK9t1HZMHHa+S9KQOs41oArpg7Ut5cvFomzf5c4hISpXqF4pKYdMEcvyp3hHz28iBzGx0GzDD7JjzYURa9dL806/Wi+W8EgBwwJrF58/8lQSoxMVHOnz/vc5w0CKpFy1Y+l4cMGyHv/+dd2bZ1iykS7+51r9m//sd1AWohgPT66oefzZaWJwd3kqXf75DHXvrYs2//b394fm5cu7yUKVFYGt01Wf5KSDT77nv8Lfn92+ekxfWV5et1u/z8CJATESQG4exmncU8ePBgKVKkiERFRZmxit4bkJKOWf3yi8/l3LmzUqtWnUA3B0Am0vHp7ZvWkD2HjssnswbJwRUxsmrBKOnU4jrPOZERYSYtTDp/0bMvMemiXLrkkia1KwSo5cjuQkNC/LZlVwEvEkePHi0rV66U2bNnS2RkpLz++utmjGKJEiVkwYIFf3v9pKQkiYuL89l0H3KePbt3SaP6daRBnZry9MQJMnX6LKlQsWKgmwUgExUplFfyReWWUX1ukmWrf5ZOD8yUT77eKv958T5pWu9/v+8/bj8gCefOy9PDukie3OGm+/nZkbdKWFguKXY1vU9AjikSP/30U3n55ZelW7duEhYWJjfeeKOMGzdOnnnmGVm4cOHfXj8mJsZMevHenp8ckyVtR9YqW7acvL9osbz97vtyx513yfhHH5Ff9+4NdLMAZKLQ0P99LH32zXaZsfBr2bb7iLwwb5l88d0O6X97U3Psj1Px0vPhN+TmZtfKHz+8KMe+e16i8+aRTT8fkkuMR8QVCvHjll0FfEziyZMnpXz58p7xh3pZNW3aVB544IG/vf7YsWNl5MiRPvtcuSL91FoEUnhEhJm4oqrXuFZ2/LRdFr69QB5/gm/mAXIKLQAvXEiWnft+99m/a1+sNKnzv88KtWLtL1Kj85NSuECUXLx4Sc7En5P9y56RA0s3BqDVQM4U8CRRC8T9+/ebn6tWrSrvv/++J2EsUKDA315fu6i1uPTedB9yvkuXLsmFFBOdAGRvFy4my8afD0rlMkV99lcqU0QO/f6/5W+8/Xk6wRSIzRtUNl3Vn327PQtbixyFKDH4ksQ+ffqYb1fRWc5jxoyRTp06ycyZM80s56lTpwa6eQgSL019UZre2EyKFS8uZxMS5IvPP5MN63+U2a++YY7/ceKE/PHHH3L40CFzee+e3XLVVVFSvHhxiU7HHxsAsk5UngipUOoaz+WyJQvLdZVLyqm4s2YdxKlvLpe3JveV7zftlW837Ja2TaqbruV2/V/yXOeezo1k1/5YOXEqXhpeV05eGH276Z7ec/B4gB4VkPOEuIJsQamDBw/Kxo0bpVKlSlKzZs0ruo3E/5vwhhxiwvhH5ce1a+XEieOSN18+qVy5ivTp118aN7nBHJ89a4bMeXmmdb2Jk2Kky623BaDF8JeCDQYHugn4h26sV0m+en2Ytf+tT9bKgAlvm597dWkko/u2lZJFCsjug8dl0pzPzThFt6eGdpa7OzWSQtFXycGjJ+X1/34v099emaWPA5nv3Gb7v+NZZd2vZ/x22w0r/N8XhmQnASsSdUazLn2zdu1aay3EM2fOmAW258yZYyayZBRFIpBzUSQCORdFYnAJDeTX8vXv3z/VxbJ1hvL9998vU6ZMCUjbAACAs+hyhv7asquAFYk6DrF9+/ZpHm/btq3pdgYAAPA35q0EUZF47Nixy35fs66ZeOLEiSxtEwAAAAJcJJYsWVJ++umnNI9v27bNzEwFAADwO6LE4CkSb775Zhk/frwkJv7vy9m9nTt3TiZMmCC33HJLQNoGAADgdAGb3azdzXXr1pVcuXKZWc5VqlQx+3/55ReZNWuWJCcny6ZNm6RoUd8FVdOD2c1AzsXsZiDnCuTs5g374/x22/XLZc/vFA/YYtpa/K1evdp89Z5+tZ67Vg0JCZF27dqZQvFKCkQAAABk829cKVOmjHzxxRdy6tQp2bt3rykUdRHtggULBrJZAADAYbLzUjU59mv5lBaFDRo0CHQzAAAAEOiJKwAAAMEimCY3HzlyRO6++24pXLiw5MmTx3xN8YYNGzzHtef18ccfN6vA6PE2bdrInj17JLNRJAIAAARJlXjq1Cm54YYbzFrSX375pfz888/y4osv+gzFe+6552T69Onm64vXrVsnUVFRZj5HaivGZPvuZgAAAIhMnjxZSpUqJfPmzfPsK1eunE+KqF9tPG7cOOnSpYvZt2DBAjPZd/HixdKjR49MawtJIgAAcLwQP/4vKSlJ4uLifDbdl5pPPvlE6tevL3fccYcUKVJE6tSpI6+99prn+P79+yU2NtZ0MbtFR0dLw4YNZc2aNZn6nFAkAgAA+FFMTIwp5Lw33Zeaffv2yezZs81qL0uXLjVLBQ4dOlTefPNNc1wLRJVymUC97D6WWehuBgAAjufPJXDGjh0rI0eO9NkXGRmZ6rmXLl0ySeIzzzxjLmuSqF9jrOMPe/fuLVmJJBEAAMCPIiMjJX/+/D5bWkWizliuXr26z75q1arJoUOHzM/FihXzfHOdN73sPpZZKBIBAIDjBcnkZtGZzbt27fLZt3v3bvMFJO5JLFoMrlixwnNcxzjqLOfGjRtLZqK7GQAAIEiMGDFCmjRpYrqbu3fvLj/++KO8+uqrZnN/ffHw4cNl0qRJZtyiFo3jx4+XEiVKSNeuXTO1LRSJAAAAQfK1fA0aNJCPPvrIjGOcOHGiKQJ1yZuePXt6znn44YclISFBBgwYIKdPn5amTZvKkiVLJHfu3JnalhCXLriTwyReDHQLAPhLwQaDA90EAH5ybvPMgN33tsPxfrvt60rlleyIMYkAAACw0N0MAAAcz59L4GRXJIkAAACwkCQCAADHI0i0kSQCAADAQpIIAABAlGghSQQAAICFJBEAADheCFGihSQRAAAAFpJEAADgeKyTaKNIBAAAjkeNaKO7GQAAABaSRAAAAKJEC0kiAAAALCSJAADA8VgCx0aSCAAAAAtJIgAAcDyWwLGRJAIAAMBCkggAAByPINFGkQgAAECVaKG7GQAAABaSRAAA4HgsgWMjSQQAAICFJBEAADgeS+DYSBIBAABgIUkEAACOR5BoI0kEAACAhSQRAACAKNFCkQgAAByPJXBsdDcDAADAQpIIAAAcjyVwbCSJAAAAsJAkAgAAxyNItJEkAgAAwEKSCAAAQJRoIUkEAACAhSQRAAA4Husk2igSAQCA47EEjo3uZgAAAFhIEgEAgOMRJNpIEgEAAGAhSQQAAI7HmEQbSSIAAAAsJIkAAACMSrSQJAIAAMBCkggAAByPMYk2ikQAAOB41Ig2upsBAABgIUkEAACOR3ezjSQRAAAAFpJEAADgeCGMSrSQJAIAAMBCkggAAECQaCFJBAAAgIUkEQAAOB5Boo0iEQAAOB5L4NjobgYAAAhSzz77rISEhMjw4cM9+xITE2XQoEFSuHBhyZs3r3Tr1k2OHTuW6fdNkQgAABwvxI//u1Lr16+XV155Ra677jqf/SNGjJBPP/1UPvjgA/n222/l6NGjctttt0lmo0gEAAAIMvHx8dKzZ0957bXXpGDBgp79Z86ckTfeeEOmTJkirVq1knr16sm8efNk9erVsnbt2kxtA0UiAABAiP+2pKQkiYuL89l03+Vod3LHjh2lTZs2Pvs3btwoFy5c8NlftWpVKV26tKxZsyZTnxKKRAAAAD+KiYmR6Ohon033peU///mPbNq0KdVzYmNjJSIiQgoUKOCzv2jRouZYZmJ2MwAAcDx/Tm4eO3asjBw50mdfZGRkqucePnxYhg0bJsuWLZPcuXNLIFEkAgAA+FFkZGSaRWFK2p18/PhxqVu3rmdfcnKyrFq1SmbOnClLly6V8+fPy+nTp33SRJ3dXKxYsUxtN0UiAABwvGBZJ7F169ayfft2n319+vQx4w4feeQRKVWqlISHh8uKFSvM0jdq165dcujQIWncuHGmtoUiEQAAON4/WaomM+XLl0+uvfZan31RUVFmTUT3/n79+pnu60KFCkn+/PllyJAhpkBs1KhRpraFIhEAACAbmTp1qoSGhpokUWdJt2vXTl5++eVMv58Ql8vlkhwm8WKgWwDAXwo2GBzoJgDwk3ObZwbsvk+dTfbbbRe8KpdkRyyBAwAAAAtFIgAAACwUiQAAALAwcQUAADhesCyBE0xIEgEAAGAhSQQAAI4XLOskBhOKRAAA4Hh0N9vobgYAAICFJBEAADgeQaKNJBEAAAAWkkQAAACiRAtJIgAAACwkiQAAwPFYAsdGkggAAAALSSIAAHA81km0kSQCAADAQpIIAAAcjyDRRpEIAABAlWihuxkAAAAWkkQAAOB4LIFjI0kEAACAhSQRAAA4Hkvg2EgSAQAAYAlxuVwuezeQPSQlJUlMTIyMHTtWIiMjA90cAJmI328gsCgSka3FxcVJdHS0nDlzRvLnzx/o5gDIRPx+A4FFdzMAAAAsFIkAAACwUCQCAADAQpGIbE0Hs0+YMIFB7UAOxO83EFhMXAEAAICFJBEAAAAWikQAAABYKBIBAABgoUgEAACAhSIRQefee++VkJAQs4WHh0vRokXlpptukrlz58qlS5cC3TwAmSQ2NlaGDBki5cuXNzOYS5UqJZ06dZIVK1ak6/rz58+XAgUK+L2dgFNRJCIotW/fXn7//Xc5cOCAfPnll9KyZUsZNmyY3HLLLXLx4sVANw/AP6S/2/Xq1ZOVK1fK888/L9u3b5clS5aY3/VBgwYFunkAKBIRrDRVKFasmJQsWVLq1q0rjz76qHz88cemYNT0QB06dEi6dOkiefPmNd/r2r17dzl27JjP7UyaNEmKFCki+fLlk/vuu0/GjBkjtWvXDtCjAuD24IMPmt6CH3/8Ubp16yaVK1eWGjVqyMiRI2Xt2rXmnClTpkjNmjUlKirKpIx6nfj4eHPsm2++kT59+pjvdXb3PDzxxBMBflRAzkKRiGyjVatWUqtWLfnwww9Nt7MWiCdPnpRvv/1Wli1bJvv27ZM777zTc/7ChQvl6aeflsmTJ8vGjRuldOnSMnv27IA+BgBifm81NdTEUAvAlNxdyKGhoTJ9+nTZsWOHvPnmmyZ1fPjhh82xJk2ayLRp08wfiNrroNuoUaOy/LEAOVlYoBsAZETVqlVl27ZtZsySdk/t37/fJAxqwYIFJolYv369NGjQQGbMmCH9+vUzaYN6/PHH5auvvvIkEQACY+/evaLf46C/z5czfPhwz89ly5Y1PQMDBw6Ul19+WSIiIiQ6OtokiNrrACDzkSQiW9EPFv1Q2LlzpykO3QWiql69ukkg9JjatWuXXH/99T7XT3kZQNZL7xd9LV++XFq3bm2GneiQkXvuuUf+/PNPOXv2rN/bCIAiEdmMFoDlypULdDMA/AOVKlUyf+z98ssvl53YohPVrrvuOlm0aJEZMjJr1ixz7Pz581nYWsC5KBKRbeh4JO1i1kHu1apVk8OHD5vN7eeff5bTp0+bRFFVqVLFdD17S3kZQNYrVKiQtGvXzhR9CQkJ1nH9PdaiUMcev/jii9KoUSMzseXo0aM+52mXc3Jycha2HHAWikQEpaSkJLOG2pEjR2TTpk3yzDPPmIkqmiz06tVL2rRpY2Y99uzZ0xzXGZK6v3nz5lK/fn1zG7r+2htvvGEGvO/Zs8eMZ9LxjJpgAAgsLRC1wNMhIJoU6u+o9hToRJXGjRtLxYoV5cKFC2ZssU5Ke+utt2TOnDk+t6HjFHWMsY5R/uOPP+iGBjKbCwgyvXv31gFLZgsLC3Ndc801rjZt2rjmzp3rSk5O9px38OBBV+fOnV1RUVGufPnyue644w5XbGysz21NnDjRdfXVV7vy5s3r6tu3r2vo0KGuRo0aBeBRAUjp6NGjrkGDBrnKlCnjioiIcJUsWdL8Tn/99dfm+JQpU1zFixd35cmTx9WuXTvXggULzH8XTp065bmNgQMHugoXLmz2T5gwIYCPBsh5QvT/Mr3yBIKUfnOLzoTUVAIAAKSNJXCQY2nXk3ZP6dinXLlyybvvvmtmS+qaigAA4PJIEpFjnTt3znwP7ObNmyUxMdFMZBk3bpzcdtttgW4aAABBjyIRAAAAFmY3AwAAwEKRCAAAAAtFIgAAACwUiQAAALBQJAIAAMBCkQggaN17773StWtXz+UWLVrI8OHDs7wd33zzjfk6R/1OYQBwCopEAFdUvGnRpFtERIT5nt2JEyfKxYsX/Xq/H374oTz11FPpOpfCDgD+Gb5xBcAVad++vcybN0+SkpLkiy++kEGDBkl4eLiMHTvW57zz58+bQjIzFCpUKFNuBwDw90gSAVyRyMhI8z3YZcqUkQceeEDatGkjn3zyiaeL+Omnn5YSJUqYb7pRhw8flu7du0uBAgVMsdelSxc5cOCA5/aSk5Nl5MiR5njhwoXl4YcflpRr/afsbtYC9ZFHHpFSpUqZ9mii+cYbb5jbbdmypTmnYMGCJlHUdqlLly5JTEyMlCtXTvLkySO1atWS//73vz73o0Vv5cqVzXG9He92AoBTUCQCyBRaUGlqqFasWCG7du0y35P92WefyYULF8x3aOfLl0++++47+eGHHyRv3rwmjXRf58UXX5T58+fL3Llz5fvvv5eTJ0/KRx99dNn77NWrl/lO7unTp8vOnTvllVdeMberReOiRYvMOdqO33//XV566SVzWQvEBQsWmO/13rFjh4wYMULuvvtu+fbbbz3FrH51o36l45YtW+S+++6TMWPG+PnZA4DgQ3czgH9E0z4tCpcuXSpDhgyREydOSFRUlLz++uuebua3337bJHi6T1M9pV3Vmhrq2MG2bdvKtGnTTFe1+7u1tYjT20zL7t275f333zeFqKaYqnz58lbXdJEiRcz9uJPHZ555RpYvXy6NGzf2XEeLUi0wmzdvLrNnz5YKFSqYolVpErp9+3aZPHmyn55BAAhOFIkArogmhJraaUqoBeC///1veeKJJ8zYxJo1a/qMQ9y6davs3bvXJIneEhMT5ddff5UzZ86YtK9hw4aeY2FhYVK/fn2ry9lNU75cuXKZwi69tA1nz56Vm266yWe/ppl16tQxP2si6d0O5S4oAcBJKBIBXBEdq6epmxaDOvZQizo3TRK9xcfHS7169WThwoXW7VxzzTVX3L2dUdoO9fnnn0vJkiV9jumYRgDA/6FIBHBFtBDUiSLpUbduXXnvvfdM12/+/PlTPad48eKybt06adasmbmsy+ls3LjRXDc1mlZqgqljCd3dzd7cSaZOiHGrXr26KQYPHTqUZgJZrVo1MwHH29q1a9P1OAEgJ2HiCgC/69mzp1x99dVmRrNOXNm/f78Zizh06FD57bffzDnDhg2TZ599VhYvXiy//PKLPPjgg5dd47Bs2bLSu3dv6du3r7mO+zZ1nKLSWdc6/lG7xXWcpKaI2t09atQoM1nlzTffNF3dmzZtkhkzZpjLauDAgbJnzx4ZPXq0mfTyzjvvmAk1AOA0FIkA/O6qq66SVatWSenSpc3EFE3r+vXrZ8YkupPFhx56SO655x5T+OkYQC3obr311svernZ333777aagrFq1qvTv318SEhLMMe1OfvLJJ83M5KJFi8rgwYPNfl2Me/z48WaWs7ZDZ1hr97MuiaO0jTozWgtPXR5HJ9DoZBcAcJoQV1qjwgEAAOBYJIkAAACwUCQCAADAQpEIAAAAC0UiAAAALBSJAAAAsFAkAgAAwEKRCAAAAAtFIgAAACwUiQAAALBQJAIAAMBCkQgAAABJ6f8B5K4K0hwj0eIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Dog       0.81      0.67      0.73       200\n",
      "         Cat       0.72      0.84      0.78       200\n",
      "\n",
      "    accuracy                           0.76       400\n",
      "   macro avg       0.76      0.76      0.75       400\n",
      "weighted avg       0.76      0.76      0.75       400\n",
      "\n",
      "\n",
      "4. Training transfer learning model...\n",
      "Transfer model parameters: 15,110,977\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\DogVsCat-classification-using-CNN\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 0.6423 - loss: 0.7242\n",
      "Epoch 1: val_accuracy improved from None to 0.69500, saving model to transfer_learning_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 513ms/step - accuracy: 0.6925 - loss: 0.6389 - val_accuracy: 0.6950 - val_loss: 1.6157 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.8318 - loss: 0.4099\n",
      "Epoch 2: val_accuracy did not improve from 0.69500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 492ms/step - accuracy: 0.8125 - loss: 0.4442 - val_accuracy: 0.6125 - val_loss: 2.6064 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.8342 - loss: 0.4292\n",
      "Epoch 3: val_accuracy did not improve from 0.69500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 499ms/step - accuracy: 0.8280 - loss: 0.4122 - val_accuracy: 0.5950 - val_loss: 2.8067 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.8450 - loss: 0.3697\n",
      "Epoch 4: val_accuracy improved from 0.69500 to 0.73750, saving model to transfer_learning_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 499ms/step - accuracy: 0.8535 - loss: 0.3533 - val_accuracy: 0.7375 - val_loss: 1.0392 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.8601 - loss: 0.3369\n",
      "Epoch 5: val_accuracy improved from 0.73750 to 0.81000, saving model to transfer_learning_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 488ms/step - accuracy: 0.8565 - loss: 0.3367 - val_accuracy: 0.8100 - val_loss: 0.5689 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.8756 - loss: 0.3039\n",
      "Epoch 6: val_accuracy improved from 0.81000 to 0.87250, saving model to transfer_learning_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 491ms/step - accuracy: 0.8745 - loss: 0.3039 - val_accuracy: 0.8725 - val_loss: 0.3696 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - accuracy: 0.8706 - loss: 0.3261\n",
      "Epoch 7: val_accuracy improved from 0.87250 to 0.88250, saving model to transfer_learning_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 496ms/step - accuracy: 0.8680 - loss: 0.3192 - val_accuracy: 0.8825 - val_loss: 0.3466 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.8848 - loss: 0.2867\n",
      "Epoch 8: val_accuracy improved from 0.88250 to 0.91750, saving model to transfer_learning_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 488ms/step - accuracy: 0.8810 - loss: 0.2877 - val_accuracy: 0.9175 - val_loss: 0.2002 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.9010 - loss: 0.2576\n",
      "Epoch 9: val_accuracy did not improve from 0.91750\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 488ms/step - accuracy: 0.8815 - loss: 0.2916 - val_accuracy: 0.8825 - val_loss: 0.3305 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.8734 - loss: 0.2887\n",
      "Epoch 10: val_accuracy did not improve from 0.91750\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 488ms/step - accuracy: 0.8850 - loss: 0.2738 - val_accuracy: 0.8150 - val_loss: 0.5236 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.8922 - loss: 0.2643\n",
      "Epoch 11: val_accuracy did not improve from 0.91750\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 486ms/step - accuracy: 0.8850 - loss: 0.2709 - val_accuracy: 0.9150 - val_loss: 0.2006 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.8945 - loss: 0.2681\n",
      "Epoch 12: val_accuracy did not improve from 0.91750\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 487ms/step - accuracy: 0.8940 - loss: 0.2463 - val_accuracy: 0.8950 - val_loss: 0.2519 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 0.8831 - loss: 0.2596\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.91750\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 502ms/step - accuracy: 0.8920 - loss: 0.2550 - val_accuracy: 0.9125 - val_loss: 0.2116 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - accuracy: 0.9145 - loss: 0.2381\n",
      "Epoch 14: val_accuracy improved from 0.91750 to 0.94250, saving model to transfer_learning_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 494ms/step - accuracy: 0.9225 - loss: 0.2139 - val_accuracy: 0.9425 - val_loss: 0.1679 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.9232 - loss: 0.1983\n",
      "Epoch 15: val_accuracy improved from 0.94250 to 0.94500, saving model to transfer_learning_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 492ms/step - accuracy: 0.9130 - loss: 0.2247 - val_accuracy: 0.9450 - val_loss: 0.1573 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.9211 - loss: 0.1849\n",
      "Epoch 16: val_accuracy did not improve from 0.94500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 495ms/step - accuracy: 0.9195 - loss: 0.1919 - val_accuracy: 0.8750 - val_loss: 0.2682 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.9268 - loss: 0.1835\n",
      "Epoch 17: val_accuracy did not improve from 0.94500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 487ms/step - accuracy: 0.9270 - loss: 0.1821 - val_accuracy: 0.9400 - val_loss: 0.1784 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.9102 - loss: 0.2160\n",
      "Epoch 18: val_accuracy did not improve from 0.94500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 488ms/step - accuracy: 0.9215 - loss: 0.2042 - val_accuracy: 0.9425 - val_loss: 0.1643 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.9184 - loss: 0.1876\n",
      "Epoch 19: val_accuracy did not improve from 0.94500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 488ms/step - accuracy: 0.9135 - loss: 0.1944 - val_accuracy: 0.9300 - val_loss: 0.1695 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - accuracy: 0.9239 - loss: 0.1532\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.94500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 495ms/step - accuracy: 0.9300 - loss: 0.1618 - val_accuracy: 0.9100 - val_loss: 0.2171 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.9181 - loss: 0.1949\n",
      "Epoch 21: val_accuracy did not improve from 0.94500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 493ms/step - accuracy: 0.9250 - loss: 0.1798 - val_accuracy: 0.9325 - val_loss: 0.1559 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.9336 - loss: 0.1546\n",
      "Epoch 22: val_accuracy did not improve from 0.94500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 504ms/step - accuracy: 0.9390 - loss: 0.1568 - val_accuracy: 0.8850 - val_loss: 0.2440 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - accuracy: 0.9413 - loss: 0.1544\n",
      "Epoch 23: val_accuracy did not improve from 0.94500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 497ms/step - accuracy: 0.9420 - loss: 0.1458 - val_accuracy: 0.9225 - val_loss: 0.2025 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.9342 - loss: 0.1644\n",
      "Epoch 24: val_accuracy did not improve from 0.94500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 490ms/step - accuracy: 0.9410 - loss: 0.1477 - val_accuracy: 0.9300 - val_loss: 0.1714 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - accuracy: 0.9391 - loss: 0.1290\n",
      "Epoch 25: val_accuracy did not improve from 0.94500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 538ms/step - accuracy: 0.9415 - loss: 0.1430 - val_accuracy: 0.8875 - val_loss: 0.3076 - learning_rate: 2.5000e-04\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 353ms/step\n",
      "Final Test Accuracy: 0.9450\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Dog       0.97      0.92      0.94       200\n",
      "         Cat       0.92      0.97      0.95       200\n",
      "\n",
      "    accuracy                           0.94       400\n",
      "   macro avg       0.95      0.95      0.94       400\n",
      "weighted avg       0.95      0.94      0.94       400\n",
      "\n",
      "\n",
      "5. Creating ensemble prediction...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 329ms/step\n",
      "Ensemble Accuracy: 0.9350\n",
      "\n",
      "==================================================\n",
      "FINAL RESULTS COMPARISON:\n",
      "==================================================\n",
      "Improved CNN Accuracy: 0.7550\n",
      "Transfer Learning Accuracy: 0.9450\n",
      "Ensemble Accuracy: 0.9350\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    improved_model, transfer_model, final_accuracy = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
